---
title: "Class7"
author: "Maris Sala"
date: "3/4/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
set.seed(1982)
#setwd("~/Aarhus University/Advanced cog mod/progre")
pacman::p_load(extraDistr, R2jags)
```

Generate task environment
```{r}
ntrials <- 100

Aprob <- .3
Arew <- 2

Bprob <- .8
Brew <- 1

#generate a payoff matrix
payoff <- cbind(rbinom(ntrials, 1, Aprob) * Arew, rbinom(ntrials, 1, Bprob) * Brew) #why rbinom?

colSums(payoff)
```

Run the CK model
```{r}
# lets call the function we wrote
# first give it some parameters

a <- .1
beta <- 5 #consistency parameter, the higher the more consistent (less explorative) the agent is

source("R_fun/RW_CK.R")

kernel_sims <- kernel(payoff, ntrials, a, beta)

par(mfrow=c(3,1)) #plot with 3 rows and 1 column
plot(kernel_sims$CK[,1])
plot(kernel_sims$CK[,2])
plot(kernel_sims$x)

```

recovering parameters with JAGS, copied from Class6
```{r}
X <- kernel_sims$x
r <- kernel_sims$r

data <- list("X", "r", "ntrials")
params <- c("a", "beta")

samples <- jags.parallel(data, inits = NULL, params,
                model.file = "jags_models/kernel.txt",
                n.chains = 3, n.iter = 5000, n.burnin = 1000, n.thin = 1)

a_infer <- samples$BUGSoutput$sims.list$a
beta_infer <- samples$BUGSoutput$sims.list$beta

par(mfrow=c(1,1))
plot(density(a_infer))
plot(density(beta_infer))

d <- density(a_infer)
plot(d, main="Kernal model: a")
polygon(d, col="lightblue", border="lightblue")
median(a_infer)

d <- density(beta_infer)
plot(d, main="Kernal model: beta")
polygon(d, col="lightblue", border="lightblue")
median(beta_infer)


```

Model recovery for 2 models: RW and kernel model, we should expect 50% model recovery (gotta add the 1 somewhere to improve this bad recovery)
```{r}
# Setting up task environment - copied from above
ntrials <- 100

Aprob <- .3
Arew <- 2

Bprob <- .8
Brew <- 1

#generate a payoff matrix
payoff <- cbind(rbinom(ntrials, 1, Aprob) * Arew, rbinom(ntrials, 1, Bprob) * Brew) #why rbinom?

colSums(payoff)

### --- ###

niterations <- 100 #set this higher (than 5) later plz

DICs_RW_dat <- array(0,c(niterations,2))
DICs_kernel_dat <- array(0,c(niterations,2))

for (i in 1:niterations) {
  #randomly set learning rate
  a <- runif(1,0,1)
  beta <- rgamma(1,1,1)
  
  #run both models
  source("R_fun/RW.R")
  RW_sims <- RW(payoff,ntrials,a,beta)
  
  source("R_fun/RW_CK.R")
  kernel_sims <- kernel(payoff,ntrials,a,beta)
  
  # ----------- RW simulation, RW model
  X <- RW_sims$x
  r <- RW_sims$r
  
  data <- list("X", "r", "ntrials")
  params <- c("a", "beta")
  
  RW.dat_RW.mod <- jags.parallel(data, inits = NULL, params,
                model.file = "jags_models/RW.txt",
                n.chains = 3, n.iter = 5000, n.burnin = 1000, n.thin = 1)
  
  RW.dat_Kernel.mod <- jags.parallel(data, inits = NULL, params,
                model.file = "jags_models/kernel.txt",
                n.chains = 3, n.iter = 5000, n.burnin = 1000, n.thin = 1)
  
  # ----------- Kernel simulation, kernel model
  
  X <- kernel_sims$x
  r <- kernel_sims$r
  
  data <- list("X", "r", "ntrials")
  params <- c("a", "beta")
  
  Kernel.dat_Kernel.mod <- jags.parallel(data, inits = NULL, params,
                model.file = "jags_models/kernel.txt",
                n.chains = 3, n.iter = 5000, n.burnin = 1000, n.thin = 1)
  
  Kernel.dat_RW.mod <- jags.parallel(data, inits = NULL, params,
                model.file = "jags_models/RW.txt",
                n.chains = 3, n.iter = 5000, n.burnin = 1000, n.thin = 1)
  
  # ----------- Getting numbers out
  DICs_RW_dat[i,1] <- RW.dat_RW.mod$BUGSoutput$DIC
  DICs_RW_dat[i,2] <- RW.dat_Kernel.mod$BUGSoutput$DIC
  DICs_kernel_dat[i,1] <- Kernel.dat_Kernel.mod$BUGSoutput$DIC
  DICs_kernel_dat[i,2] <- Kernel.dat_RW.mod$BUGSoutput$DIC
  
  print(i); beepr::beep(sound=1)
}

best_RW <- array(0,c(niterations))
best_kernel <- array(0,c(niterations))
for (i in 1:niterations) {
  best_RW[i] <- which.min(DICs_RW_dat[i,])
  best_kernel[i] <- which.min(DICs_kernel_dat[i,])
}

# Here we want to see that number 1 gets put out - to show that X data with X model performs best
best_RW
best_kernel

```

Ludvig's package for confusion matrix
```{r}
#save.image(file='kernal_rw_model_recovery.RData')

#devtools::install_github("tidyverse/broom")
library(broom)
library(cvms)
#library(tidyverse)
library(tibble)

#remove.packages("broom")

# 0 is best model
best_kernel
bk = replace(best_kernel, best_kernel==1, 0)
bk = replace(bk, bk == 2, 1)

# 1 is best model
best_RW
brw = replace(best_RW, best_RW==2, 0)

# combine
tg = c(brw, bk)

# Results in a tibble
d_confusion <- tibble("target" = c(runif(length(best_RW),1,1), runif(length(best_kernel),0,0)),
                      "prediction" = tg)

cfm <- tidy(table(d_confusion))

plot_confusion_matrix(cfm,
                      targets_col = "target",
                      predictions_col = "prediction",
                      counts_col = "n")

```


Parameter recovery
```{r}
#run full parameter recovery
niterations <- 100
true_a <- array(0, c(niterations))
true_beta <- array(0, c(niterations))

infer_a <- array(0,c(niterations))
infer_beta <- array(0,c(niterations))

##

for (i in 1:niterations) {
  # true parameters
  a <- runif(1,0,1)
  beta <- runif(1,0,5)
  
  #fun function and extract responses
  source("R_fun/RW.R")
  RW_sims <- RW(payoff, ntrials, a, beta)
  X <- RW_sims$x
  r <- RW_sims$r
  
  data <- list("X", "r", "ntrials")
  params <- c("a", "beta")

  samples <- jags.parallel(data, inits = NULL, params,
                  model.file = "jags_models/RW.txt",
                  n.chains = 3, n.iter = 5000, n.burnin = 1000, n.thin = 1)
  true_a[i] <- a
  true_beta[i] <- beta
  
  #find max posteriori
  X <- samples$BUGSoutput$sims.list$a
  infer_a[i] <- density(X)$x[which(density(X)$y==max(density(X)$y))]
  
  X <- samples$BUGSoutput$sims.list$beta
  infer_beta[i] <- density(X)$x[which(density(X)$y==max(density(X)$y))]
  
  print(i); beepr::beep(sound=1)
}

plot(true_a, infer_a)

source("quick_n_clean_plots.R")
gridExtra::grid.arrange(
  plot_actual_predicted(true_a,infer_a),
  plot_actual_predicted(true_beta,infer_beta),
  ncol = 2
)
```

```{r}
#full parameter recovery for kernel model

#run full parameter recovery
niterations <- 100
kernel_true_a <- array(0, c(niterations))
kernel_true_beta <- array(0, c(niterations))

kernel_infer_a <- array(0,c(niterations))
kernel_infer_beta <- array(0,c(niterations))

##

for (i in 1:niterations) {
  # true parameters
  a <- runif(1,0,1)
  beta <- runif(1,0,5)
  
  #fun function and extract responses
  source("R_fun/RW_CK.R")
  kernel_sims <- kernel(payoff, ntrials, a, beta)
  X <- kernel_sims$x
  r <- kernel_sims$r
  
  data <- list("X", "r", "ntrials")
  params <- c("a", "beta")

  samples <- jags.parallel(data, inits = NULL, params,
                  model.file = "jags_models/kernel.txt",
                  n.chains = 3, n.iter = 5000, n.burnin = 1000, n.thin = 1)
  kernel_true_a[i] <- a
  kernel_true_beta[i] <- beta
  
  #find max posteriori
  X <- samples$BUGSoutput$sims.list$a
  kernel_infer_a[i] <- density(X)$x[which(density(X)$y==max(density(X)$y))]
  
  X <- samples$BUGSoutput$sims.list$beta
  kernel_infer_beta[i] <- density(X)$x[which(density(X)$y==max(density(X)$y))]
  
  print(i); beepr::beep(sound=1)
}

plot(kernel_true_a, kernel_infer_a)
plot(kernel_true_beta, kernel_infer_beta)

source("quick_n_clean_plots.R")
gridExtra::grid.arrange(
  plot_actual_predicted(kernel_true_a,kernel_infer_a),
  plot_actual_predicted(kernel_true_beta,kernel_infer_beta),
  ncol = 2
)

#get plotting functions
source("quick_n_clean_plots.R")
infer_a
#Beautiful plots
image_a = plot_actual_predicted(kernel_true_a,kernel_infer_a, caption = F)+
  ggtitle("Kernal model: a") +
  theme_bw() +
  xlim(0,1) + ylim(0,1)
image_beta = plot_actual_predicted(kernel_true_beta,kernel_infer_beta, caption = F)+
  ggtitle("Kernal model: beta") +
  theme_bw() +
  xlim(0,5) + ylim(0,5)

img_rw_model <-  gridExtra::grid.arrange(image_a, image_beta, nrow=1)
```

