---
title: "Class13"
author: "Maris Sala"
date: "4/1/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
This is the IGT task with actual data instead of simulated one. Posterior predictive checks of descriptive adequacy

Setup
```{r}
set.seed(1982)
#setwd("~/Aarhus University/Advanced cog mod/progre")
pacman::p_load(extraDistr, R2jags)

# load control data
ctr_data <- read.table("rawData/IGTdata_healthy_control.txt", header=T)
```

Prepare the data for the JAGS model
Turning it into a matrix
```{r}
# Identify and count unique subject IDs
subIDs <- unique(ctr_data$subjID)
nsubs <- length(subIDs)
ntrials_max <- 100

# All choices (x) and outcomes (X)
x_raw <- ctr_data$deck
X_raw <- ctr_data$gain + ctr_data$loss
```

Assign choices and outcomes in trial x sub matrix
Different number of trials across subjects. We'll need to fix this by padding arrays of < 100. Then we'll also need to record number of valid trials for each sub, then run the JAGS model on only valid trials!
```{r}
# Empty arrays to fill
ntrials_all <- array(0, c(nsubs))
x_all <- array(0, c(nsubs, ntrials_max))
X_all <- array(0, c(nsubs, ntrials_max))

# Fill the arrays! Loop over subjects
for (s in 1:nsubs) {
  #record n trials for subject s. Count number of trials for subject
  ntrials_all[s] <- length(x_raw[ctr_data$subjID==subIDs[s]])
  
  #pad trials with NA if n trials < maximum (i e 100)
  x_sub <- x_raw[ctr_data$subjID==subIDs[s]]
  length(x_sub) <- ntrials_max
  
  X_sub <- X_raw[ctr_data$subjID==subIDs[s]]
  length(X_sub) <- ntrials_max
  #^temporary data for subject s, padded with NA where there are no trials, the NA's do NOT get into JAGS!
  
  #assign arrays
  x_all[s,] <- x_sub
  X_all[s,] <- X_sub
}
```

Applying the model to data
```{r}
#Testing on one subject whether this works
x <- x_all[1,]
X <- X_all[1,]

ntrials <- ntrials_all[1]

# Set up jags and run jags model on one subject
data <- list("x", "X", "ntrials")
params <- c("w", "A", "theta", "a", "p")
samples <- jags.parallel(data, inits = NULL, params,
                model.file = "jags_models/PVL.txt",
                n.chains = 3, n.iter = 5000, n.burnin = 1000, n.thin = 1)
##NOTE: turn off truncation in the JAGS file for A (violates prospect theory but necessary for this to run) - runs fine for me

# Checking the posteriors
par(mfrow=c(2,2))
plot(density(samples$BUGSoutput$sims.list$w))
plot(density(samples$BUGSoutput$sims.list$A))
plot(density(samples$BUGSoutput$sims.list$theta))
plot(density(samples$BUGSoutput$sims.list$a))
```

Posterior prediction. How reliable is what we say about the world in the previous posteriors?
Q: How would you expect the data to look on the basis of these posteriors?
```{r}
# Posterior prediction - start by looking at posteriors for p parameter
p_post <- samples$BUGSoutput$sims.list$p #the output of the softmax

#plot probability of each deck on trial 32
par(mfrow=c(2,2))
plot(density(p_post[,32,1]))
plot(density(p_post[,32,2]))
plot(density(p_post[,32,3]))
plot(density(p_post[,32,4]))

# which option will be chosen?
x[32]

# Model guesses 3, actual choice is 3
```

The model won't always get this right. Relevant questions: How often? Above chance? Better than other models?
```{r}
# Let's write a loop to find out!
x_predict <- array(c(ntrials))
for (t in 1:ntrials) {
  p_predict <- c(
    density(p_post[,t,1])$x[which(density(p_post[,t,1])$y==max(density(p_post[,t,1])$y))],
    density(p_post[,t,2])$x[which(density(p_post[,t,2])$y==max(density(p_post[,t,2])$y))],
    density(p_post[,t,3])$x[which(density(p_post[,t,3])$y==max(density(p_post[,t,3])$y))],
    density(p_post[,t,4])$x[which(density(p_post[,t,4])$y==max(density(p_post[,t,4])$y))])
  
  x_predict[t] <- which.max(p_predict)
}

# How many correct out of 100 trials for this participant:
sum(x_predict==x)
```

Finding how well the model performs on all the subjects
```{r}
pred_success <- array(c(nsubs))
for (s in 1:nsubs) {
  
  # fit jags model
  x <- x_all[s,]
  X <- X_all[s,]
  
  ntrials <- ntrials_all[s]
  
  # Set up jags and run jags model on one subject
  data <- list("x", "X", "ntrials")
  params <- c("w", "A", "theta", "a", "p")
  samples <- jags.parallel(data, inits = NULL, params,
                           model.file = "jags_models/PVL.txt",
                           n.chains = 3, n.iter = 5000, n.burnin = 1000, n.thin = 1) #n.thin = 3, n.iter = 10000, decorrelates the chains
  
  p_post <- samples$BUGSoutput$sims.list$p
  
  x_predict <- array(c(ntrials))
  for (t in 1:ntrials) {
    p_predict <- c(
      density(p_post[,t,1])$x[which(density(p_post[,t,1])$y==max(density(p_post[,t,1])$y))],
      density(p_post[,t,2])$x[which(density(p_post[,t,2])$y==max(density(p_post[,t,2])$y))],
      density(p_post[,t,3])$x[which(density(p_post[,t,3])$y==max(density(p_post[,t,3])$y))],
      density(p_post[,t,4])$x[which(density(p_post[,t,4])$y==max(density(p_post[,t,4])$y))])
    
    x_predict[t] <- which.max(p_predict)
  }
  
  # How many correct out of 100 trials for each participant:
  pred_success[s] <- sum(x_predict==x, na.rm=T)
  print(s)
}
```

Visualize predicted success
```{r}
#write.csv(pred_success, "predicted_success.csv", row.names = F)

pred_success = read.csv("predicted_success.csv")
library(ggplot2)

PVL = ggplot(pred_success, aes(x)) +
  geom_density()

PVL = PVL +
  ggtitle("PVL: Posterior predictive checks") +
  geom_vline(xintercept=25, color = "red") +
  theme_bw()

median(pred_success$x)
sum(pred_success$x<=25)
sum(pred_success$x>25)

length(pred_success$x)
```

Predicted success for ORL
```{r}
pred_success <- array(c(nsubs))
for (s in 1:nsubs) {
  
  # fit jags model
  x <- x_all[s,]
  r <- X_all[s,]
  
  ntrials <- ntrials_all[s]
  
  # Set up jags and run jags model on one subject
  data <- list("x", "r", "ntrials")
  params <- c("a_rew", "a_pun", "beta_f", "beta_p", "K", "theta", "p")
  samples <- jags.parallel(data, inits = NULL, params,
                           model.file = "jags_models/ORL.txt",
                           n.chains = 3, n.iter = 5000, n.burnin = 1000, n.thin = 1) #n.thin = 3, n.iter = 10000, decorrelates the chains
  
  p_post <- samples$BUGSoutput$sims.list$p
  
  x_predict <- array(c(ntrials))
  for (t in 1:ntrials) {
    p_predict <- c(
      density(p_post[,t,1])$x[which(density(p_post[,t,1])$y==max(density(p_post[,t,1])$y))],
      density(p_post[,t,2])$x[which(density(p_post[,t,2])$y==max(density(p_post[,t,2])$y))],
      density(p_post[,t,3])$x[which(density(p_post[,t,3])$y==max(density(p_post[,t,3])$y))],
      density(p_post[,t,4])$x[which(density(p_post[,t,4])$y==max(density(p_post[,t,4])$y))])
    
    x_predict[t] <- which.max(p_predict)
  }
  
  # How many correct out of 100 trials for each participant:
  pred_success[s] <- sum(x_predict==x, na.rm=T)
  print(s);beepr::beep(sound=1)
};beepr::beep(sound=5)

write.csv(pred_success, "predicted_success_ORL.csv", row.names = F)
```

Visualizing the scores
```{r}
pred_success = read.csv("predicted_success_ORL.csv")
library(ggplot2)

ORL = ggplot(pred_success, aes(x)) +
  geom_density()

ORL = ORL +
  ggtitle("ORL: Posterior predictive checks") +
  geom_vline(xintercept=25, color = "red") +
  theme_bw()

median(pred_success$x)
sum(pred_success$x<=25)
sum(pred_success$x>25)

length(pred_success$x)
```





Posterior predictive checks for VSE

Losses and gains separate for VSE
```{r}
# All choices (x) and outcomes (X)
x_raw <- ctr_data$deck
g_raw <- ctr_data$gain
l_raw <- ctr_data$loss

# Empty arrays to fill
ntrials_all <- array(0, c(nsubs))
x_all <- array(0, c(nsubs, ntrials_max))
g_all <- array(0, c(nsubs, ntrials_max))
l_all <- array(0, c(nsubs, ntrials_max))

# Fill the arrays! Loop over subjects
for (s in 1:nsubs) {
  #record n trials for subject s. Count number of trials for subject
  ntrials_all[s] <- length(x_raw[ctr_data$subjID==subIDs[s]])
  
  #pad trials with NA if n trials < maximum (i e 100)
  x_sub <- x_raw[ctr_data$subjID==subIDs[s]]
  length(x_sub) <- ntrials_max
  
  g_sub <- g_raw[ctr_data$subjID==subIDs[s]]
  length(g_sub) <- ntrials_max
  #^temporary data for subject s, padded with NA where there are no trials, the NA's do NOT get into JAGS!
  
  l_sub <- l_raw[ctr_data$subjID==subIDs[s]]
  length(l_sub) <- ntrials_max
  
  #assign arrays
  x_all[s,] <- x_sub
  l_all[s,] <- l_sub
  g_all[s,] <- g_sub
}

l_all = abs(l_all)
```

```{r}
pred_success <- array(c(nsubs))
for (s in 1:nsubs) {
  
  # fit jags model
  x <- x_all[s,]
  r <- g_all[s,]
  l <- l_all[s,]
  
  ntrials <- ntrials_all[s]
  
  # Set up jags and run jags model on one subject
  data <- list("x", "r", "l", "ntrials")
  params <- c("r_pref", "delta_rate", "a_explore", "phi", "theta", "p")
  samples <- jags.parallel(data, inits = NULL, params,
                           model.file = "jags_models/VSE.txt",
                           n.chains = 3, n.iter = 5000, n.burnin = 1000, n.thin = 1) #n.thin = 3, n.iter = 10000, decorrelates the chains
  
  p_post <- samples$BUGSoutput$sims.list$p
  
  x_predict <- array(c(ntrials))
  for (t in 1:ntrials) {
    p_predict <- c(
      density(p_post[,t,1])$x[which(density(p_post[,t,1])$y==max(density(p_post[,t,1])$y))],
      density(p_post[,t,2])$x[which(density(p_post[,t,2])$y==max(density(p_post[,t,2])$y))],
      density(p_post[,t,3])$x[which(density(p_post[,t,3])$y==max(density(p_post[,t,3])$y))],
      density(p_post[,t,4])$x[which(density(p_post[,t,4])$y==max(density(p_post[,t,4])$y))])
    
    x_predict[t] <- which.max(p_predict)
  }
  
  # How many correct out of 100 trials for each participant:
  pred_success[s] <- sum(x_predict==x, na.rm=T)
  print(s);beepr::beep(sound=2)
}
write.csv(pred_success, "predicted_success_VSE.csv", row.names = F)
```

Visualizing results

```{r}
pred_success = read.csv("predicted_success_VSE.csv")
library(ggplot2)

VSE = ggplot(pred_success, aes(x)) +
  geom_density()

VSE = VSE + 
  ggtitle("VSE: Posterior predictive checks") +
  geom_vline(xintercept=25, color = "red") +
  theme_bw()

gridExtra::grid.arrange(PVL,ORL,VSE)

median(pred_success$x)
sum(pred_success$x<=25)
sum(pred_success$x>25)

length(pred_success$x)
```


